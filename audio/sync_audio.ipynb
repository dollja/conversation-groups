{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from datetime import datetime\n",
    "import wave\n",
    "import scipy.signal\n",
    "\n",
    "from conflab.constants import (\n",
    "    raw_audio_path,\n",
    "    raw_wearables_path\n",
    ")\n",
    "from utils import (\n",
    "    get_audio_chunks, \n",
    "    get_accel_chunks, \n",
    "    AudioFile\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder with accel files only from midge data\n",
    "# midge_accel_path = '/mnt/e/data/conflab/accel/midge'\n",
    "# midge_accel = os.listdir(midge_accel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate correspondance files\n",
    "\n",
    "The following cell will generate files containing a log of the missing data segments in both accel and audio raw files.\n",
    "\n",
    "Because the device malfunction affected both streams, the holes can be associated to synchronize the audio data using the timestamps in the accel data at start / end times of these holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondances_path = os.path.join(raw_audio_path, 'sync_files')\n",
    "if not os.path.exists(correspondances_path):\n",
    "    os.mkdir(correspondances_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midge_raw_data_path = os.path.join(raw_wearables_path, 'raw')\n",
    "for midge_num in os.listdir(midge_raw_data_path):\n",
    "    exp_folder = os.path.join(correspondances_path, midge_num)\n",
    "    if not os.path.exists(exp_folder):\n",
    "        os.mkdir(exp_folder)\n",
    "\n",
    "    data_folder = os.listdir(os.path.join(midge_raw_data_path, midge_num))[-1]\n",
    "    midge_files = os.listdir(os.path.join(midge_raw_data_path, midge_num, data_folder))\n",
    "    audio_fname = [f for f in midge_files if f.endswith('_audio_1')][-1]\n",
    "    audio_fname = os.path.join(midge_raw_data_path, midge_num, data_folder, audio_fname)\n",
    "\n",
    "    accel_fname = [f for f in midge_files if f.endswith('_accel.csv')][-1]\n",
    "    accel_fname = os.path.join(midge_raw_data_path, midge_num, data_folder, accel_fname)\n",
    "    # accel_fname = list(filter(lambda f: f.startswith(f'{midge_num}_'), midge_accel))[-1]\n",
    "    # accel_fname = os.path.join(midge_accel_path, accel_fname)\n",
    "\n",
    "    # audio holes\n",
    "    audio_file = AudioFile(audio_fname)\n",
    "    good_chunks, repeat_chunks = audio_file.get_repeats()\n",
    "    # good_chunks, repeat_chunks = get_audio_chunks(audio_fname)\n",
    "    first = np.array([chunk['first'] for chunk in repeat_chunks])\n",
    "    last = np.array([chunk['last'] for chunk in repeat_chunks])\n",
    "    tfirst = np.array([chunk['tfirst'] for chunk in repeat_chunks])\n",
    "    tlast = np.array([chunk['tlast'] for chunk in repeat_chunks])\n",
    "    df = pd.DataFrame()\n",
    "    df['first'] = first\n",
    "    df['last'] = last\n",
    "    df['len'] = (last - first)\n",
    "    df['tfirst'] = tfirst\n",
    "    df['tlast'] = tlast\n",
    "    df.to_csv(os.path.join(exp_folder, 'audio_holes.csv'))\n",
    "\n",
    "    # accel holes\n",
    "    accel_holes = get_accel_chunks(accel_fname)\n",
    "    accel_holes.to_csv(os.path.join(exp_folder, 'accel_holes.csv'))\n",
    "\n",
    "    # do the matching\n",
    "    corr = df.copy()\n",
    "    corr['accel_first'] = None\n",
    "    corr['accel_last'] = None\n",
    "\n",
    "    af = df['tfirst'].iat[0]\n",
    "    al = df['tlast'].iat[-1]\n",
    "    xf = accel_holes['time_first'].iat[0]\n",
    "    xl = accel_holes['time_last'].iat[-1]\n",
    "\n",
    "    # print((af, al, xf, xl))\n",
    "\n",
    "    for i, ah in accel_holes.iterrows():\n",
    "        \n",
    "        aft = af + (al - af) * (ah['time_first'] - xf) / (xl - xf)\n",
    "        alt = af + (al - af) * (ah['time_last'] - xf) / (xl - xf)\n",
    "\n",
    "        af_idx = corr['tfirst'].sub(aft).abs().idxmin()\n",
    "        al_idx = corr['tfirst'].sub(alt).abs().idxmin()\n",
    "\n",
    "        corr['accel_first'][af_idx] = ah['time_first']\n",
    "        corr['accel_last'][al_idx] = ah['time_last']\n",
    "\n",
    "    corr.to_csv(os.path.join(exp_folder, 'correspondance.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction code\n",
    "\n",
    "After manual correction, the correspondance files can be used to generate corrected audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annot_chunks(correspondances, af):\n",
    "\n",
    "    \n",
    "    good_chunks, repeat_chunks = af.get_repeats()\n",
    "\n",
    "    i = 0\n",
    "    annotated_good_chunks = []\n",
    "    while i < len(correspondances)-1:\n",
    "        # if not np.isnan(correspondances.loc[i, 'accel_last']):\n",
    "        while np.isnan(correspondances.loc[i, 'accel_last']) and i < len(correspondances) - 2:\n",
    "            i += 1\n",
    "\n",
    "        \n",
    "\n",
    "        accel_first = correspondances.loc[i, 'accel_last']\n",
    "        chunks = []\n",
    "        i += 1\n",
    "        if i == len(correspondances) - 1:\n",
    "            break\n",
    "        \n",
    "        chunks.append(good_chunks[i])\n",
    "\n",
    "        while np.isnan(correspondances.loc[i, 'accel_first']) and i < len(correspondances) - 1:\n",
    "            i += 1\n",
    "            chunks.append(good_chunks[i])\n",
    "\n",
    "        accel_last = correspondances.loc[i, 'accel_first']\n",
    "\n",
    "        # if len(chunks) >= 2:\n",
    "        annotated_good_chunks.append({\n",
    "            'audio_first': chunks[0]['tfirst'],\n",
    "            'audio_last': chunks[-1]['tlast'],\n",
    "            'audio_first_sample': chunks[0]['first'],\n",
    "            'audio_last_sample': chunks[-1]['last'],\n",
    "            'accel_first': accel_first,\n",
    "            'accel_last': accel_last,\n",
    "            'chunks': chunks\n",
    "        })\n",
    "    return annotated_good_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_samples(fout, samples, num_samples):\n",
    "    bytes_samples = b''.join(samples)\n",
    "    samples = [int.from_bytes(bytes_samples[i:i + 2], 'little', signed=True)\n",
    "               for i in range(0, len(bytes_samples), 2)]\n",
    "    signal = scipy.signal.resample(samples, num_samples)\n",
    "    \n",
    "    quantized = list()\n",
    "    for el in signal:\n",
    "        # âˆ’32,768 to 32,767\n",
    "        int_el = max(-32768, min(32767, int(el)))\n",
    "        int_bytes = int_el.to_bytes(2, 'little', signed=True)\n",
    "        quantized.append(int_bytes)\n",
    "    \n",
    "    quant_bytes = b''.join(quantized)\n",
    "    fout.writeframesraw(quant_bytes)\n",
    "\n",
    "    return num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_blank_until(fout, num_written, sec):\n",
    "    num_to_write = int(sec * 1250) - num_written\n",
    "    assert num_to_write > 0, f'num_to_write is {num_to_write}'\n",
    "    fout.writeframesraw(bytearray(num_to_write * 2))\n",
    "    return num_to_write # num of samples written\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_subject_audio(af, fout_name, chunks):\n",
    "    with wave.open(fout_name, 'wb') as fout:\n",
    "        fout.setnchannels(1)\n",
    "        fout.setsampwidth(2)\n",
    "        fout.setframerate(1250)\n",
    "\n",
    "        prev_intval = None\n",
    "        num_written = 0\n",
    "        for chunk in chunks:\n",
    "            print(\n",
    "                f'{\"*\"*20} \\\n",
    "accel: {chunk[\"accel_first\"]} - {chunk[\"accel_last\"]} \\\n",
    "audio: {chunk[\"audio_first\"]} - {chunk[\"audio_last\"]}\\\n",
    " ({chunk[\"audio_first_sample\"]} - {chunk[\"audio_last_sample\"]})')\n",
    "            # if chunk['audio'][1] == -1 or chunk['accel'][1] == -1:\n",
    "            #     break\n",
    "\n",
    "            # write blank data in the hole\n",
    "            num_written += write_blank_until(\n",
    "                fout, num_written, chunk['accel_first'])\n",
    "            print(f'blank: {num_written}')\n",
    "\n",
    "            # fill the good chunk with interpolated data\n",
    "            num_written += write_samples(\n",
    "                fout, \n",
    "                af.get_chunk(chunk['audio_first_sample'], chunk['audio_last_sample']),\n",
    "                round(1250 * (chunk['accel_last'] - chunk['accel_first'])))\n",
    "            print(f'data: {num_written}')\n",
    "            # print(round(1250 * (chunk['accel_last'] - chunk['accel_first'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midge_raw_data_path = os.path.join(raw_wearables_path, 'raw')\n",
    "for midge_num in os.listdir(midge_raw_data_path):\n",
    "    of_path = os.path.join(raw_audio_path, 'synced', f'{midge_num}.wav')\n",
    "    if(os.path.exists(of_path)):\n",
    "        continue\n",
    "\n",
    "    data_folder = os.listdir(os.path.join(midge_raw_data_path, midge_num))[-1]\n",
    "    midge_files = os.listdir(os.path.join(midge_raw_data_path, midge_num, data_folder))\n",
    "    audio_fname = [f for f in midge_files if f.endswith('_audio_1')][-1]\n",
    "    audio_fname = os.path.join(midge_raw_data_path, midge_num, data_folder, audio_fname)\n",
    "    af = AudioFile(audio_fname)\n",
    "\n",
    "    correspondances_fp = os.path.join(correspondances_path, f'{midge_num}/correspondance.csv')\n",
    "    correspondances = pd.read_csv(open(correspondances_fp, 'rb'))\n",
    "\n",
    "    print(f'MIDGE {midge_num}')\n",
    "    chunks = get_annot_chunks(correspondances, af)\n",
    "\n",
    "    try:\n",
    "        correct_subject_audio(af, of_path, chunks)\n",
    "    except Exception as ex:\n",
    "        os.remove(of_path)\n",
    "        raise ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ff63645dd16f55240e07095d3c46f4fac3f89ef16802cfaceca713f6cf38dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
